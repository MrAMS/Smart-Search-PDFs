#!/usr/bin/env python3
"""
æœç´¢å¼•æ“æµ‹è¯•å·¥å…·

ç”¨æ³•ï¼š
    # åŸºæœ¬æœç´¢
    python test_search.py "æ•™å­¦ç›´æ’­ç³»ç»Ÿ"

    # æŒ‡å®šé•¿åº¦æƒ©ç½šå‚æ•°
    python test_search.py "æ•™å­¦ç›´æ’­ç³»ç»Ÿ" --penalty 0.3

    # æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
    python test_search.py "æ•™å­¦ç›´æ’­ç³»ç»Ÿ" --penalty 0.3 --debug

    # å¯¹æ¯”ä¸åŒæƒ©ç½šå‚æ•°
    python test_search.py "æ•™å­¦ç›´æ’­ç³»ç»Ÿ" --compare 0.0 0.3 0.5
"""

import argparse
import json
import os
import sys
from pathlib import Path

import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from fastembed import TextEmbedding
    from search_engine import EmbeddingSearcher, SearchEngine
    FASTEMBED_AVAILABLE = True
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£… fastembed: pip install fastembed")
    sys.exit(1)


def load_corpus(data_folder):
    """
    åŠ è½½è¯­æ–™åº“ï¼ˆJSON + EMB æ–‡ä»¶ï¼‰

    Args:
        data_folder: åŒ…å« PDF/JSON/EMB æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„

    Returns:
        åŒ…å« text å’Œ embedding çš„æ–‡æ¡£åˆ—è¡¨
    """
    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_folder}")

    if not os.path.isdir(data_folder):
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {data_folder}")
        sys.exit(1)

    corpus = []
    json_files = sorted([f for f in os.listdir(data_folder) if f.endswith('.json')])

    if not json_files:
        print(f"âŒ æœªæ‰¾åˆ° JSON æ–‡ä»¶")
        sys.exit(1)

    for json_file in json_files:
        json_path = os.path.join(data_folder, json_file)
        emb_path = json_path.replace('.json', '.emb')

        # åŠ è½½ JSON
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                pages = json.load(f)
        except Exception as e:
            print(f"âš ï¸  åŠ è½½ {json_file} å¤±è´¥: {e}")
            continue

        # åŠ è½½ EMBï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists(emb_path):
            try:
                with open(emb_path, 'r', encoding='utf-8') as f:
                    emb_pages = json.load(f)

                # åˆå¹¶ embedding åˆ°å¯¹åº”çš„é¡µé¢
                for i, page in enumerate(pages):
                    if i < len(emb_pages) and 'embedding' in emb_pages[i]:
                        page['embedding'] = emb_pages[i]['embedding']
            except Exception as e:
                print(f"âš ï¸  åŠ è½½ {emb_path} å¤±è´¥: {e}")

        corpus.extend(pages)

    # ç»Ÿè®¡
    total_docs = len(corpus)
    emb_docs = sum(1 for doc in corpus if 'embedding' in doc)

    print(f"âœ… åŠ è½½å®Œæˆ: {total_docs} ä¸ªé¡µé¢")
    print(f"ğŸ“Š å…¶ä¸­ {emb_docs} ä¸ªé¡µé¢æœ‰ embedding ({emb_docs/total_docs*100:.1f}%)\n")

    return corpus


def format_filename(filename):
    """ç¼©çŸ­æ–‡ä»¶åä»¥ä¾¿æ˜¾ç¤º"""
    if len(filename) > 40:
        return filename[:37] + "..."
    return filename


def search_and_display(
    query,
    corpus,
    embed_model,
    penalty=0.3,
    top_k=10,
    debug=False
):
    """
    æ‰§è¡Œæœç´¢å¹¶æ˜¾ç¤ºç»“æœ

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        corpus: æ–‡æ¡£è¯­æ–™åº“
        embed_model: Embedding æ¨¡å‹
        penalty: é•¿åº¦æƒ©ç½šå‚æ•°
        top_k: æ˜¾ç¤ºçš„ç»“æœæ•°é‡
        debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
    """
    print(f"ğŸ” æœç´¢: '{query}'")
    print(f"âš™ï¸  é•¿åº¦æƒ©ç½š: {penalty}")
    print(f"ğŸ“ è¿”å›å‰ {top_k} ä¸ªç»“æœ\n")

    # åˆ›å»ºæœç´¢å™¨
    searcher = EmbeddingSearcher(embed_model, enable_cache=True)

    # æ‰§è¡Œæœç´¢
    results = searcher.search(
        query,
        corpus,
        max_results=top_k,
        length_penalty_exp=penalty,
        return_details=True
    )

    if not results:
        print("âŒ æœªæ‰¾åˆ°ç»“æœ")
        return

    print("=" * 80)

    for i, (idx, final_score, cosine_sim, length) in enumerate(results, 1):
        doc = corpus[idx]
        filename = doc.get('filename', 'unknown')
        page = doc.get('page_number', '?')
        text = doc.get('text', '')

        # è®¡ç®—æƒ©ç½šå› å­
        if length > 0 and penalty > 0:
            penalty_factor = length ** penalty
        else:
            penalty_factor = 1.0

        # æ˜¾ç¤ºç»“æœ
        print(f"\n{i}. {format_filename(filename)} - ç¬¬ {page} é¡µ")
        print(f"   æœ€ç»ˆåˆ†æ•°: {final_score:.4f} | ä½™å¼¦ç›¸ä¼¼åº¦: {cosine_sim:.4f}")
        print(f"   æ–‡æœ¬é•¿åº¦: {length} å­— | æƒ©ç½šå› å­: {penalty_factor:.2f}")

        if debug:
            # æ˜¾ç¤ºæ–‡æœ¬é¢„è§ˆ
            text_preview = text[:150].replace('\n', ' ')
            print(f"   é¢„è§ˆ: {text_preview}...")

            # æ˜¾ç¤ºåˆ†æ•°è®¡ç®—ç»†èŠ‚
            print(f"   è®¡ç®—: {cosine_sim:.4f} / {penalty_factor:.2f} = {final_score:.4f}")

    print("\n" + "=" * 80)

    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
    cache_stats = searcher.get_cache_stats()
    print(f"\nğŸ’¾ ç¼“å­˜ç»Ÿè®¡: å‘½ä¸­ {cache_stats['hits']} æ¬¡, "
          f"æœªå‘½ä¸­ {cache_stats['misses']} æ¬¡, "
          f"å‘½ä¸­ç‡ {cache_stats['hit_rate']*100:.1f}%")


def compare_penalties(query, corpus, embed_model, penalties, top_k=5):
    """
    å¯¹æ¯”ä¸åŒé•¿åº¦æƒ©ç½šå‚æ•°çš„æ•ˆæœ

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        corpus: æ–‡æ¡£è¯­æ–™åº“
        embed_model: Embedding æ¨¡å‹
        penalties: è¦å¯¹æ¯”çš„æƒ©ç½šå‚æ•°åˆ—è¡¨
        top_k: æ¯ä¸ªå‚æ•°æ˜¾ç¤ºçš„ç»“æœæ•°
    """
    print(f"ğŸ” æŸ¥è¯¢: '{query}'")
    print(f"âš™ï¸  å¯¹æ¯”å‚æ•°: {penalties}")
    print(f"ğŸ“ æ¯ä¸ªå‚æ•°æ˜¾ç¤ºå‰ {top_k} ä¸ªç»“æœ\n")
    print("=" * 80)

    searcher = EmbeddingSearcher(embed_model, enable_cache=True)

    for penalty in penalties:
        print(f"\nğŸ“Š é•¿åº¦æƒ©ç½š = {penalty}")
        print("-" * 80)

        results = searcher.search(
            query,
            corpus,
            max_results=top_k,
            length_penalty_exp=penalty,
            return_details=True
        )

        for i, (idx, final_score, cosine_sim, length) in enumerate(results, 1):
            doc = corpus[idx]
            filename = format_filename(doc.get('filename', 'unknown'))
            page = doc.get('page_number', '?')

            print(f"{i}. {filename:40s} p.{page:3d} | "
                  f"åˆ†æ•°: {final_score:.4f} | "
                  f"ä½™å¼¦: {cosine_sim:.4f} | "
                  f"é•¿åº¦: {length:4d}")

    print("\n" + "=" * 80)
    print("\nğŸ’¡ å»ºè®®ï¼šé€‰æ‹©ç»“æœæœ€ç›¸å…³çš„æƒ©ç½šå‚æ•°")
    print("   - æƒ©ç½š 0.0: æ— æƒ©ç½šï¼Œé•¿æ–‡æ¡£å¯èƒ½æ’åé å‰")
    print("   - æƒ©ç½š 0.2-0.4: è½»åº¦æƒ©ç½šï¼ˆæ¨èï¼‰")
    print("   - æƒ©ç½š 0.5+: ä¸­åº¦åˆ°é‡åº¦æƒ©ç½šï¼Œé•¿æ–‡æ¡£è¢«å‹åˆ¶")


def main():
    parser = argparse.ArgumentParser(
        description='æµ‹è¯• Embedding æœç´¢å¼•æ“',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # åŸºæœ¬æœç´¢
  python test_search.py "æ•™å­¦ç›´æ’­ç³»ç»Ÿ"

  # æŒ‡å®šæƒ©ç½šå‚æ•°
  python test_search.py "æ•™å­¦ç›´æ’­ç³»ç»Ÿ" --penalty 0.3

  # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
  python test_search.py "æ•™å­¦ç›´æ’­ç³»ç»Ÿ" --penalty 0.3 --debug

  # å¯¹æ¯”ä¸åŒå‚æ•°
  python test_search.py "æ•™å­¦ç›´æ’­ç³»ç»Ÿ" --compare 0.0 0.3 0.5
        """
    )

    parser.add_argument('query', help='æœç´¢æŸ¥è¯¢')
    parser.add_argument('--folder', default='/home/santiego/Downloads/åˆ†å¸ƒå¼/pdfs',
                       help='æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--penalty', type=float, default=0.3,
                       help='é•¿åº¦æƒ©ç½šæŒ‡æ•°ï¼ˆé»˜è®¤ 0.3ï¼‰')
    parser.add_argument('--top', type=int, default=10,
                       help='æ˜¾ç¤ºå‰ N ä¸ªç»“æœï¼ˆé»˜è®¤ 10ï¼‰')
    parser.add_argument('--debug', action='store_true',
                       help='æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆæ–‡æœ¬é¢„è§ˆã€åˆ†æ•°è®¡ç®—ç­‰ï¼‰')
    parser.add_argument('--compare', nargs='+', type=float,
                       help='å¯¹æ¯”å¤šä¸ªæƒ©ç½šå‚æ•°ï¼ˆä¾‹å¦‚ï¼š--compare 0.0 0.3 0.5ï¼‰')

    args = parser.parse_args()

    # åŠ è½½æ•°æ®
    corpus = load_corpus(args.folder)

    # åˆå§‹åŒ–æ¨¡å‹
    print("ğŸ”§ åˆå§‹åŒ– embedding æ¨¡å‹...")
    cache_dir = os.path.expanduser("~/.cache/fastembed")
    model_name = "jinaai/jina-embeddings-v2-base-zh"

    embed_model = TextEmbedding(model_name=model_name, cache_dir=cache_dir)
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ\n")

    # æ‰§è¡Œæœç´¢
    if args.compare:
        # å¯¹æ¯”æ¨¡å¼
        compare_penalties(args.query, corpus, embed_model, args.compare, top_k=args.top)
    else:
        # æ™®é€šæœç´¢æ¨¡å¼
        search_and_display(
            args.query,
            corpus,
            embed_model,
            penalty=args.penalty,
            top_k=args.top,
            debug=args.debug
        )


if __name__ == '__main__':
    main()
